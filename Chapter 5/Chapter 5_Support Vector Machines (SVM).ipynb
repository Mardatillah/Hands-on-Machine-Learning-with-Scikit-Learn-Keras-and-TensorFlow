{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGI52MoygUuYS2hiEANdSW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mardatillah/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow/blob/main/Chapter%205/Chapter%205_Support%20Vector%20Machines%20(SVM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Support Vector Machines (SVM)\n",
        "---\n",
        "Chapter ini membahas tentang **Support Vector Machines (SVM)**, salah satu algoritma yang sangat efektif untuk masalah klasifikasi, baik itu linier maupun non-linier. SVM bekerja dengan mencari batas yang memisahkan kelas dengan margin terbesar di antara data.\n",
        "\n",
        "1. Linear SVM Classification\n",
        "    *   **SVM Linear** adalah metode yang digunakan untuk memisahkan dua kelas dengan garis atau hiperplane dalam ruang fitur. Tujuan SVM adalah memaksimalkan **margin**, yaitu jarak antara garis pemisah (hyperplane) dan data terdekat dari kedua kelas, yang disebut **support vectors**.\n",
        "    *   **Margin** yang lebih besar umumnya memberikan model yang lebih baik, karena memiliki kemampuan generalisasi yang lebih baik terhadap data yang belum terlihat.\n",
        "2. Soft Margin Classification\n",
        "    *   Dalam kenyataannya, data tidak selalu terpisah dengan sempurna, dan beberapa titik data mungkin berada di sisi yang salah dari hyperplane. Oleh karena itu, SVM menggunakan **soft margin**, yang memungkinkan beberapa data untuk berada di sisi yang salah dari hyperplane, dengan penalti yang diatur oleh parameter **C**.\n",
        "        *   **C** mengontrol trade-off antara margin yang lebih lebar dan kesalahan klasifikasi. Nilai **C** yang besar cenderung meminimalkan kesalahan klasifikasi, tetapi mungkin menyebabkan overfitting. Sebaliknya, nilai **C** yang kecil memungkinkan margin lebih lebar, tetapi bisa mengarah pada underfitting.\n",
        "3. Nonlinear SVM Classification\n",
        "    *   **Nonlinear SVM** digunakan ketika data tidak dapat dipisahkan secara linier. Untuk menangani masalah ini, SVM menggunakan **kernel trick**, yang mengubah data ke dalam dimensi yang lebih tinggi, di mana data dapat dipisahkan secara linier.\n",
        "        *   **Kernel functions** seperti **polynomial kernel** dan G**aussian Radial Basis Function (RBF)** kernel memungkinkan SVM untuk menangani data dengan hubungan kompleks.\n",
        "4. SVM for Regression\n",
        "    *   SVM tidak hanya digunakan untuk klasifikasi, tetapi juga untuk **regresi**. SVM untuk regresi (SVR) berusaha memprediksi nilai kontinu, dengan konsep dasar yang mirip dengan klasifikasi, tetapi fokus pada memperkecil kesalahan prediksi daripada margin.\n",
        "        *   **Epsilon-SVR** adalah bentuk SVM yang digunakan untuk regresi, di mana model mencoba untuk menemukan fungsi yang meminimalkan kesalahan prediksi dalam batas epsilon.\n",
        "5. Under the Hood: How SVM Works\n",
        "    *   SVM bekerja dengan mencari **optimal hyperplane** yang memisahkan dua kelas, yang dioptimalkan menggunakan teknik **quadratic programming** untuk memaksimalkan margin.\n",
        "    *   Konsep **dual problem** digunakan dalam SVM, yang memungkinkan untuk bekerja dalam ruang fitur yang lebih tinggi tanpa secara eksplisit menghitung koordinat data di ruang tersebut, berkat kernel trick.\n",
        "6. Training SVM\n",
        "    *   Melatih SVM melibatkan pencarian hyperplane yang optimal. Untuk ini, teknik seperti **Sequential Minimal Optimization (SMO)** sering digunakan untuk memecahkan masalah optimisasi kuadrat dalam waktu yang efisien.\n",
        "\n",
        "### Poin-poin Utama:\n",
        "*   **Linear SVM** memisahkan kelas dengan hyperplane dan memaksimalkan margin untuk meningkatkan generalisasi.\n",
        "*   **Soft Margin SVM** memungkinkan beberapa kesalahan klasifikasi untuk menangani data yang tidak terpisahkan dengan sempurna.\n",
        "*   **Nonlinear SVM** menggunakan kernel trick untuk menangani data yang tidak terpisahkan secara linier.\n",
        "*   **SVM for Regression (SVR)** memprediksi nilai kontinu dengan prinsip yang mirip dengan klasifikasi.\n",
        "*   **Dual Problem** dan **Kernel Functions** memungkinkan SVM untuk bekerja lebih efisien dalam ruang fitur yang lebih tinggi.\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ2sV76-ZD57"
      }
    }
  ]
}