{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzpNT7PgSpRZmUpkKsLaVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mardatillah/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow/blob/main/Chapter%208/Chapter%208_Dimensionality%20Reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 8: Dimensionality Reduction\n",
        "---\n",
        "Chapter ini membahas **Dimensionality Reduction** (reduksi dimensi), yaitu teknik untuk mengurangi jumlah fitur dalam dataset sambil mempertahankan informasi penting. Tujuannya adalah untuk meningkatkan efisiensi model, mempercepat proses pelatihan, dan menghindari masalah seperti **curse of dimensionality**.\n",
        "\n",
        "1. The Curse of Dimensionality\n",
        "    *   **Curse of Dimensionality** mengacu pada masalah yang timbul ketika jumlah fitur (dimensi) dalam dataset sangat besar. Dengan semakin banyaknya fitur, model menjadi lebih kompleks, dan data menjadi lebih sparse, yang bisa menurunkan kinerja model.\n",
        "    *   Dimensionality reduction membantu dengan mengurangi jumlah fitur sambil mencoba mempertahankan sebanyak mungkin informasi yang relevan.\n",
        "2. Main Approaches for Dimensionality Reduction\n",
        "Ada dua pendekatan utama untuk reduksi dimensi:\n",
        "    *   **Projection:** Mengubah data ke dalam ruang fitur yang lebih rendah tanpa kehilangan banyak informasi penting.\n",
        "    *   **Manifold Learning:** Menganggap bahwa data dalam dimensi tinggi sebenarnya berada di ruang manifol yang lebih rendah. Teknik ini bertujuan untuk menemukan ruang yang lebih rendah di mana data dapat diproyeksikan tanpa kehilangan struktur.\n",
        "3. Principal Component Analysis (PCA)\n",
        "    *   **PCA** adalah teknik reduksi dimensi yang paling banyak digunakan. PCA mengidentifikasi **principal components** (komponen utama), yang merupakan kombinasi linier dari fitur-fitur asli, yang paling menggambarkan variansi dalam data.\n",
        "    *   Tujuan PCA adalah mengurangi dimensi data dengan mempertahankan sebagian besar variansi informasi dalam dataset.\n",
        "        *   **Explained Variance Ratio:** Mengukur seberapa banyak variansi yang dijelaskan oleh setiap komponen utama.\n",
        "        *   **Choosing the Right Number of Dimensions:** Memilih jumlah dimensi yang tepat untuk menghindari kehilangan informasi yang penting.\n",
        "4. Randomized PCA\n",
        "    *   **Randomized PCA** adalah variasi dari PCA yang lebih cepat untuk dataset besar. Ia menggunakan pendekatan stokastik untuk menemukan komponen utama, yang memungkinkan untuk reduksi dimensi yang lebih efisien.\n",
        "5. Incremental PCA\n",
        "    *   **Incremental PCA** adalah variasi PCA yang memungkinkan untuk melatih model pada data dalam batch kecil, yang sangat berguna untuk dataset besar yang tidak muat dalam memori.\n",
        "6. Kernel PCA\n",
        "    *   **Kernel PCA** adalah perluasan dari PCA yang memungkinkan reduksi dimensi pada data non-linier. Kernel PCA menggunakan kernel trick untuk memetakan data ke ruang fitur yang lebih tinggi, di mana data mungkin lebih mudah dipisahkan.\n",
        "7. Locally Linear Embedding (LLE)\n",
        "    *   **LLE** adalah teknik pembelajaran manifol yang mengurangi dimensi dengan memproyeksikan data ke ruang dimensi lebih rendah sambil menjaga hubungan antara titik-titik terdekat di dalam data.\n",
        "8. t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
        "    *   **t-SNE** adalah teknik visualisasi yang sangat efektif untuk mengurangi dimensi data dan memperlihatkan struktur data yang kompleks dalam dua atau tiga dimensi.\n",
        "    *   Teknik ini sering digunakan untuk visualisasi data dalam pembelajaran mesin, terutama untuk dataset yang sangat besar atau beragam.\n",
        "9. When to Use Dimensionality Reduction\n",
        "    *   **PCA dan teknik reduksi dimensi lainnya** sangat berguna ketika:\n",
        "          *   Data memiliki banyak fitur tetapi tidak banyak informasi baru ditambahkan oleh setiap fitur tambahan.\n",
        "          *   Dataset memiliki redundansi yang dapat dihapus untuk meningkatkan efisiensi komputasi.\n",
        "          *   Dimensionality reduction juga membantu dalam mengatasi masalah overfitting dengan mengurangi kompleksitas model.\n",
        "\n",
        "### Poin-poin Utama:\n",
        "*   **Curse of Dimensionality** terjadi ketika dataset memiliki banyak fitur yang tidak relevan, yang bisa menurunkan performa model.\n",
        "*   **PCA** adalah teknik utama dalam reduksi dimensi, yang mengurangi dimensi dengan mempertahankan variansi data.\n",
        "*   **Randomized PCA** dan **Incremental PCA** adalah teknik untuk mempercepat dan mempermudah PCA pada dataset besar.\n",
        "*   **Kernel PCA** dan **t-SNE** adalah teknik untuk menangani data non-linier dan visualisasi data.\n",
        "*   **Dimensionality Reduction** membantu meningkatkan efisiensi komputasi, mempercepat pelatihan model, dan mengurangi risiko overfitting."
      ],
      "metadata": {
        "id": "YJ2sV76-ZD57"
      }
    }
  ]
}