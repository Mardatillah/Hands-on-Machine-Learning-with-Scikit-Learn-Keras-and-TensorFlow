{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOtu5FQUNsmotBi1WHpQbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mardatillah/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow/blob/main/Chapter%206/Chapter%206_Decision%20Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6: Decision Trees\n",
        "---\n",
        "Pada chapter ini, dibahas tentang **Decision Trees**, yang merupakan algoritma yang digunakan baik untuk klasifikasi maupun regresi. Decision Trees membagi data menjadi subset berdasarkan fitur yang memiliki nilai terbaik untuk memisahkan data ke dalam kelas atau nilai yang berbeda.\n",
        "\n",
        "1. Training and Visualizing a Decision Tree\n",
        "    *   **Decision Trees** bekerja dengan membagi data ke dalam cabang-cabang berdasarkan fitur yang paling memisahkan kelas atau nilai. Pembagian ini dilakukan pada setiap node menggunakan fitur yang memberikan informasi paling banyak (misalnya, menggunakan **Gini impurity** atau **entropy** dalam klasifikasi).\n",
        "    *   Setelah model dibangun, pohon keputusan dapat divisualisasikan untuk mempermudah pemahaman bagaimana model membuat keputusan berdasarkan data.\n",
        "2. Making Predictions\n",
        "    *   Prediksi dilakukan dengan mengikuti jalur dari akar (root) pohon hingga mencapai daun (leaf), yang berisi prediksi akhir. Jalur tersebut tergantung pada nilai fitur yang diberikan oleh data input.\n",
        "        *   Untuk klasifikasi, daun akan berisi kelas prediksi.\n",
        "        *   Untuk regresi, daun berisi nilai prediksi rata-rata dari data pada cabang tersebut.\n",
        "3. Estimating Class Probabilities\n",
        "    *   Decision Trees tidak hanya memberikan prediksi kelas tetapi juga dapat menghitung probabilitas kelas. Probabilitas ini dihitung berdasarkan proporsi data dalam setiap daun, yang memungkinkan model untuk memberikan perkiraan tingkat kepercayaan terhadap prediksi yang dibuat.\n",
        "4. The CART Training Algorithm\n",
        "    *   **CART (Classification and Regression Trees)** adalah algoritma yang digunakan untuk melatih Decision Trees. Proses pelatihan dimulai dengan memilih fitur terbaik untuk membagi data di setiap langkah, menggunakan kriteria seperti **Gini impurity** untuk klasifikasi dan **variance reduction** untuk regresi.\n",
        "5. Gini Impurity and Entropy\n",
        "    *   **Gini impurity** digunakan untuk mengukur kualitas pemisahan data pada node. Nilai Gini yang lebih rendah menunjukkan pembagian yang lebih baik.\n",
        "    *   **Entropy** adalah ukuran lain untuk kebaikan pemisahan, yang digunakan dalam beberapa variasi Decision Tree. Entropy mengukur ketidakpastian dalam data, dan tujuan pohon keputusan adalah untuk mengurangi entropy pada setiap pembagian.\n",
        "6. Regularization Hyperparameters\n",
        "    *   **Hyperparameters** seperti **max_depth** (kedalaman maksimum pohon), **min_samples_split** (jumlah sampel minimum untuk memecah node), dan **min_samples_leaf** (jumlah sampel minimum pada daun) digunakan untuk mengatur kompleksitas pohon dan mencegah **overfitting**.\n",
        "        *   Pengaturan hyperparameter ini penting untuk membangun pohon yang generalisasi dengan baik pada data yang tidak terlihat.\n",
        "7. Regression with Decision Trees\n",
        "    *   Selain klasifikasi, Decision Trees juga dapat digunakan untuk **regresi**, di mana pohon membuat prediksi nilai kontinu. Pembagian pada setiap node dilakukan untuk meminimalkan varians dalam data, dengan tujuan menghasilkan nilai prediksi yang lebih akurat.\n",
        "8. Instability of Decision Trees\n",
        "    *   Salah satu kelemahan utama Decision Trees adalah **instabilitas**. Model ini sangat sensitif terhadap perubahan kecil dalam data pelatihan. Meskipun dapat menangani data dengan baik, pohon keputusan seringkali dapat sangat berubah jika ada sedikit perubahan pada data pelatihan.\n",
        "\n",
        "\n",
        "### Poin-poin Utama:\n",
        "*   **Decision Trees** membagi data berdasarkan fitur untuk memprediksi kelas atau nilai target.\n",
        "*   **CART Algorithm** digunakan untuk membangun pohon keputusan, dengan menggunakan kriteria seperti **Gini impurity** dan **entropy**.\n",
        "*   **Pruning** dan **regularization** digunakan untuk menghindari overfitting dengan membatasi kedalaman pohon dan jumlah sampel pada node.\n",
        "*   Decision Trees dapat digunakan untuk **regresi** dengan memprediksi nilai kontinu dan menghitung rata-rata nilai di setiap daun.\n",
        "*   **Instabilitas** adalah masalah utama, di mana pohon keputusan dapat sangat sensitif terhadap data pelatihan.\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ2sV76-ZD57"
      }
    }
  ]
}